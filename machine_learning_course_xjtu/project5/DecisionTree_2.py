# ===============================
# ğŸ“Š å®é™…æ•°æ®é›† + ä¸å¹³è¡¡åˆ†ç±» + æ¨¡å‹æ¯”è¾ƒ
# ===============================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    roc_auc_score, precision_score, recall_score,
    classification_report, ConfusionMatrixDisplay
)
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from imblearn.over_sampling import SMOTE

# 1ï¸âƒ£ è½½å…¥ï¼ˆä¹³è…ºç™Œæ•°æ®é›†ï¼‰

# 30ä¸ªç‰¹å¾
# 569ä¸ªæ ·æœ¬
# 2ä¸ªç±»åˆ«ï¼ˆ0ï¼šè‰¯æ€§ï¼Œ1ï¼šæ¶æ€§ï¼‰
data_raw = load_breast_cancer(as_frame=True) # as_frame=True è¿”å› DataFrame æ ¼å¼
X = data_raw.data
y = data_raw.target

feature_names = X.columns
print("æ•°æ®é›†å½¢çŠ¶:", X.shape)
print("ç±»åˆ«åˆ†å¸ƒ:", np.bincount(y))
print(f"ç±»åˆ«æ¯”ä¾‹: {np.bincount(y)[1] / len(y):.3f} ä¸ºæ­£æ ·æœ¬")

# 2ï¸âƒ£ é¢œè‰²æ˜ å°„ + å¯è§†åŒ–éƒ¨åˆ†ï¼ˆæŠ½å–éƒ¨åˆ†ç‰¹å¾çœ‹åˆ†å¸ƒï¼‰
# é¢œè‰²æ˜ å°„ï¼š0 - é»„è‰²ï¼Œ1 - çº¢è‰²
color_map = {0: "yellow", 1: "red"}
color_list = [color_map[val] for val in y]

fig, axs = plt.subplots(3, 4, figsize=(18, 10), dpi=80)
axs = axs.flatten()
x_coord = np.linspace(0, len(y)-1, len(y))

for i, col in enumerate(feature_names[:len(axs)]):
    axs[i].scatter(x_coord, X[col], color=color_list, s=5)
    axs[i].set_title(col)
    axs[i].set_xlabel("Sample Index")
    axs[i].set_ylabel(col)

plt.tight_layout()
plt.show()

# 3ï¸âƒ£ åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)
print(f"è®­ç»ƒé›†æ­£æ ·æœ¬æ¯”ä¾‹: {y_train.mean():.3f}")

# 4ï¸âƒ£ æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 5ï¸âƒ£ SMOTE å¹³è¡¡
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
print(f"SMOTE åæ­£æ ·æœ¬æ¯”ä¾‹: {y_train_res.mean():.3f}")

# 6ï¸âƒ£ å®šä¹‰æ¨¡å‹
models = {
    "Decision Tree": DecisionTreeClassifier(max_depth=5, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=8, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
}

# 7ï¸âƒ£ æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°
results = []
for name, model in models.items():
    model.fit(X_train_res, y_train_res)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]
    
    auc = roc_auc_score(y_test, y_prob)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    
    print(f"\n=== {name} ===")
    print(f"AUC: {auc:.3f}")
    print(f"Precision: {precision:.3f}")
    print(f"Recall: {recall:.3f}")
    print(classification_report(y_test, y_pred))
    
    results.append((name, auc, precision, recall))
    
    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
    plt.title(f"{name} Confusion Matrix")
    plt.show()

# 8ï¸âƒ£ æ¨¡å‹æŒ‡æ ‡å¯è§†åŒ–
model_names = [r[0] for r in results]
auc_scores = [r[1] for r in results]
precisions = [r[2] for r in results]
recalls = [r[3] for r in results]

plt.figure(figsize=(10, 6))
x = np.arange(len(model_names))
width = 0.25

plt.bar(x - width, auc_scores, width=width, label="AUC")
plt.bar(x, precisions, width=width, label="Precision")
plt.bar(x + width, recalls, width=width, label="Recall")
plt.xticks(x, model_names)
plt.title("Model Performance Comparisonï¼ˆAUC / Precision / Recallï¼‰")
plt.ylabel("Score")
plt.legend()
plt.tight_layout()
plt.show()
