import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, RocCurveDisplay
from sklearn.preprocessing import FunctionTransformer

def add_features(X):
    X = X.copy()
    X["family_size"] = X["sibsp"] + X["parch"] + 1 # äº¤äº’ç‰¹å¾
    # ç¥¨ä»·å¯¹æ•°å˜æ¢
    X["fare_log"] = np.log1p(X["fare"]) # å‡å°‘æç«¯å€¼å½±å“
    return X

#  1. åŠ è½½ Titanic æ•°æ®é›†ï¼ˆæ¥è‡ª seabornï¼‰
df = sns.load_dataset("titanic").dropna(subset=["survived"])
print("âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå…±", df.shape[0], "è¡Œ")

#  2. é€‰æ‹©éƒ¨åˆ†æœ‰ä»£è¡¨æ€§çš„ç‰¹å¾ 
X = df[["pclass", "sex", "age", "sibsp", "parch", "fare", "embarked"]]
y = df["survived"]

#  3. åŒºåˆ†ç‰¹å¾ç±»å‹  
num_cols = ["age", "sibsp", "parch", "fare"] # æ•°å€¼å‹ç‰¹å¾
cat_cols = ["pclass", "sex", "embarked"] # ç±»åˆ«å‹ç‰¹å¾

#  4. æ•°æ®é¢„å¤„ç† 
feature_adder = FunctionTransformer(add_features) # è‡ªå®šä¹‰ç‰¹å¾æ·»åŠ å™¨

# å…ˆåŠ æ–°ç‰¹å¾ï¼Œå†åšæ•°å€¼/ç±»åˆ«å¤„ç†
preprocessor = Pipeline([
    ("add", feature_adder),
    ("col", ColumnTransformer([
        ("num", Pipeline([
            ("imputer", SimpleImputer(strategy="median")),
            ("scaler", StandardScaler())
        ]), num_cols + ["family_size", "fare_log"]),
        ("cat", Pipeline([
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("onehot", OneHotEncoder(handle_unknown="ignore"))
        ]), cat_cols)
    ]))
])

#  5. æ•°æ®åˆ’åˆ† 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

#  6. æ¨¡å‹å®šä¹‰ä¸å‚æ•°ç½‘æ ¼ 
models = {
    "DecisionTree": (DecisionTreeClassifier(random_state=42),
                     {"clf__max_depth": [None, 3, 5, 8, 10, 15]}), # [none, 5, 10] ä¸‰ç§æ·±åº¦é€‰æ‹©,è¿™ä¸ªå‚æ•°ä¼šä¼ é€’ç»™æµæ°´çº¿ä¸­çš„åˆ†ç±»å™¨
    "RandomForest": (RandomForestClassifier(random_state=42, n_jobs=-1), # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
                     {"clf__n_estimators": [50, 100, 200, 300, 500], "clf__max_depth": [None, 3, 5, 8, 10, 15]}) # æ£®æ—ä¸­æ ‘çš„æ•°é‡å’Œæ·±åº¦é€‰æ‹©
}

results = []

#  7. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼° 
for name, (model, grid) in models.items(): # grid æ˜¯å‚æ•°ç½‘æ ¼
    pipe = Pipeline([("pre", preprocessor), ("clf", model)]) # æ„å»ºæµæ°´çº¿
    search = GridSearchCV(pipe, grid, cv=5, scoring="f1_macro", n_jobs=-1) # ç½‘æ ¼æœç´¢ï¼Œ5æŠ˜äº¤å‰éªŒè¯ï¼Œè¯„ä¼°æŒ‡æ ‡ä¸º F1 åˆ†æ•°
    search.fit(X_train, y_train)
    best = search.best_estimator_ # æœ€ä½³æ¨¡å‹

    y_pred = best.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print(f"\nğŸŒ² {name}")
    print("æœ€ä½³å‚æ•°:", search.best_params_)
    print(f"å‡†ç¡®ç‡: {acc:.4f}, F1åˆ†æ•°: {f1:.4f}")

    # æ··æ·†çŸ©é˜µå¯è§†åŒ–
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

    # ROC æ›²çº¿ï¼ˆä»…äºŒåˆ†ç±»ï¼‰
    RocCurveDisplay.from_estimator(best, X_test, y_test)
    plt.title(f"{name} ROC Curve")
    plt.show()

    results.append({"Model": name, "Accuracy": acc, "F1": f1})

#  8. æ¨¡å‹æ€§èƒ½å¯¹æ¯” 
res_df = pd.DataFrame(results)
print("\næ¨¡å‹å¯¹æ¯”ç»“æœï¼š")
print(res_df)

sns.barplot(data=res_df.melt(id_vars="Model", var_name="Metric", value_name="Score"),
            x="Model", y="Score", hue="Metric")
plt.title("å†³ç­–æ ‘ vs éšæœºæ£®æ— æ€§èƒ½å¯¹æ¯”")
plt.ylim(0, 1)
plt.show()
